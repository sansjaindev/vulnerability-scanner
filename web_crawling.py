import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
from queue import Queue
import threading


threads = 10
base_url = "http://demo.testfire.net"
base_domain = urlparse(base_url).netloc
visited_urls = set()
urls_to_visit = Queue()
urls_to_visit.put(base_url)

def scrape_links():
    while not urls_to_visit.empty():
        url = urls_to_visit.get()
        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.text, "html.parser")
            links = soup.find_all("a", href=True)
            for link in links:
                href = link.get("href")
                if href and href not in visited_urls and href != '#':
                    print(f"[+] Found new link: {href}")
                    visited_urls.add(href)
                    absolute_url = urljoin(base_url, href)
                    if urlparse(absolute_url).netloc == base_domain:
                        urls_to_visit.put(absolute_url)
                    
                        # print(f"[+] Found new link: {absolute_url}")
        except requests.ConnectionError:
            pass


def create_threads():
    for _ in range(threads):
        t = threading.Thread(target=scrape_links)
        t.start()


def main():
    create_threads()

if __name__ == "__main__":
    main()